{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2jbN5l0plZ_"
      },
      "source": [
        "Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtjESIVkpN-S",
        "outputId": "4830b7a4-1756-439d-ebc5-14f205659e5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,776 kB]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,986 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,037 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,296 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,750 kB]\n",
            "Fetched 20.2 MB in 5s (4,046 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "35 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpci3 pci.ids usb.ids\n",
            "The following NEW packages will be installed:\n",
            "  libpci3 lshw pci.ids pciutils usb.ids\n",
            "0 upgraded, 5 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 883 kB of archives.\n",
            "After this operation, 3,256 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 pci.ids all 0.0~2022.01.22-1ubuntu0.1 [251 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libpci3 amd64 1:3.7.0-6 [28.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 lshw amd64 02.19.git.2021.06.19.996aaad9c7-2build1 [321 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 pciutils amd64 1:3.7.0-6 [63.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 usb.ids all 2022.04.02-1 [219 kB]\n",
            "Fetched 883 kB in 2s (416 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 5.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package pci.ids.\n",
            "(Reading database ... 126111 files and directories currently installed.)\n",
            "Preparing to unpack .../pci.ids_0.0~2022.01.22-1ubuntu0.1_all.deb ...\n",
            "Unpacking pci.ids (0.0~2022.01.22-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libpci3:amd64.\n",
            "Preparing to unpack .../libpci3_1%3a3.7.0-6_amd64.deb ...\n",
            "Unpacking libpci3:amd64 (1:3.7.0-6) ...\n",
            "Selecting previously unselected package lshw.\n",
            "Preparing to unpack .../lshw_02.19.git.2021.06.19.996aaad9c7-2build1_amd64.deb ...\n",
            "Unpacking lshw (02.19.git.2021.06.19.996aaad9c7-2build1) ...\n",
            "Selecting previously unselected package pciutils.\n",
            "Preparing to unpack .../pciutils_1%3a3.7.0-6_amd64.deb ...\n",
            "Unpacking pciutils (1:3.7.0-6) ...\n",
            "Selecting previously unselected package usb.ids.\n",
            "Preparing to unpack .../usb.ids_2022.04.02-1_all.deb ...\n",
            "Unpacking usb.ids (2022.04.02-1) ...\n",
            "Setting up pci.ids (0.0~2022.01.22-1ubuntu0.1) ...\n",
            "Setting up lshw (02.19.git.2021.06.19.996aaad9c7-2build1) ...\n",
            "Setting up usb.ids (2022.04.02-1) ...\n",
            "Setting up libpci3:amd64 (1:3.7.0-6) ...\n",
            "Setting up pciutils (1:3.7.0-6) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "✅ Dependencies installed\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update && sudo apt install pciutils lshw -y\n",
        "print(\"✅ Dependencies installed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1B5wy5Kp4rQ"
      },
      "source": [
        "Install Ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QnCChOjp65v",
        "outputId": "cd991f34-6e65-450a-f64c-8fed8b5b6b2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Cleaning up old version at /usr/local/lib/ollama\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "######################################################################## 100.0%\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            ">>> NVIDIA GPU installed.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n",
            "✅ Ollama installed\n"
          ]
        }
      ],
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "print(\"✅ Ollama installed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBWJ75uKqB9e"
      },
      "source": [
        "Start Ollama server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Sd9Vd3XQqqMK"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE3AVtamqs3x"
      },
      "source": [
        "Start Ollama server in background"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFZyynHwqwSY",
        "outputId": "0e2ed849-d35c-4448-939b-46c8f82f0295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Starting Ollama server...\n",
            "✅ Ollama server running\n"
          ]
        }
      ],
      "source": [
        "process = subprocess.Popen(['ollama', 'serve'],\n",
        "                          stdout=subprocess.PIPE,\n",
        "                          stderr=subprocess.PIPE)\n",
        "print(\"🚀 Starting Ollama server...\")\n",
        "time.sleep(10)  # Wait for server to initialize\n",
        "print(\"✅ Ollama server running\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Sbts9dFq1TX"
      },
      "source": [
        "Pull phi3:mini model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDFtPz4Sq3G0",
        "outputId": "dc7d47b8-c90c-4462-877a-a1bb031d1d5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "✅ phi3:mini model downloaded\n"
          ]
        }
      ],
      "source": [
        "!ollama pull phi3:mini\n",
        "print(\"✅ phi3:mini model downloaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTW0uY5Sq688"
      },
      "source": [
        "Verify everything is working\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fjc6nkXsq8zS",
        "outputId": "f87e6a91-5f73-4f0b-e7ec-b9d30b5f102f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NAME         ID              SIZE      MODIFIED      \n",
            "phi3:mini    4f2222927938    2.2 GB    6 seconds ago    \n"
          ]
        }
      ],
      "source": [
        "!ollama list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBzPpmn0rNVF"
      },
      "source": [
        "Test phi3:mini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2S1DYiSrOlq",
        "outputId": "e38186de-2468-40bd-f06b-c4cc0593d847"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?25l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[2K\u001b[1G\u001b[?25hO\u001b[?25l\u001b[?25hui\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h bien\u001b[?25l\u001b[?25h s\u001b[?25l\u001b[?25hû\u001b[?25l\u001b[?25hr\u001b[?25l\u001b[?25h!\u001b[?25l\u001b[?25h Je\u001b[?25l\u001b[?25h suis\u001b[?25l\u001b[?25h là\u001b[?25l\u001b[?25h pour\u001b[?25l\u001b[?25h répond\u001b[?25l\u001b[?25hre\u001b[?25l\u001b[?25h à\u001b[?25l\u001b[?25h v\u001b[?25l\u001b[?25hos\u001b[?25l\u001b[?25h questions\u001b[?25l\u001b[?25h aussi\u001b[?25l\u001b[?25h cla\u001b[?25l\u001b[?25hirement\u001b[?25l\u001b[?25h que\u001b[?25l\u001b[?25h possible\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h Cependant\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h je\u001b[?25l\u001b[?25h ne\u001b[?25l\u001b[?25h puis\u001b[?25l\u001b[?25h pas\u001b[?25l\u001b[?25h rec\u001b[?25l\u001b[?25hue\u001b[?25l\u001b[?25hill\u001b[?25l\u001b[?25hir\u001b[?25l\u001b[?25h de\u001b[?25l\u001b[?25h données\u001b[?25l\u001b[?25h personn\u001b[?25l\u001b[?25helles\u001b[?25l\u001b[?25h ou\u001b[?25l\u001b[?25h f\u001b[?25l\u001b[?25hourn\u001b[?25l\u001b[?25hir\u001b[?25l\u001b[?25h une\u001b[?25l\u001b[?25h assistance\u001b[?25l\u001b[?25h clin\u001b[?25l\u001b[?25hique\u001b[?25l\u001b[?25h en\u001b[?25l\u001b[?25h tant\u001b[?25l\u001b[?25h qu\u001b[?25l\u001b[?25h'\u001b[?25l\u001b[?25hass\u001b[?25l\u001b[?25histant\u001b[?25l\u001b[?25h I\u001b[?25l\u001b[?25hA\u001b[?25l\u001b[?25h bas\u001b[?25l\u001b[?25hé\u001b[?25l\u001b[?25h sur\u001b[?25l\u001b[?25h des\u001b[?25l\u001b[?25h informations\u001b[?25l\u001b[?25h pré\u001b[?25l\u001b[?25hexist\u001b[?25l\u001b[?25hantes\u001b[?25l\u001b[?25h et\u001b[?25l\u001b[?25h non\u001b[?25l\u001b[?25h exper\u001b[?25l\u001b[?25htes\u001b[?25l\u001b[?25h dans\u001b[?25l\u001b[?25h la\u001b[?25l\u001b[?25h médec\u001b[?25l\u001b[?25hine\u001b[?25l\u001b[?25h comme\u001b[?25l\u001b[?25h un\u001b[?25l\u001b[?25h profession\u001b[?25l\u001b[?25hnel\u001b[?25l\u001b[?25h hum\u001b[?25l\u001b[?25hain\u001b[?25l\u001b[?25h le\u001b[?25l\u001b[?25h serait\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h Si\u001b[?25l\u001b[?25h vous\u001b[?25l\u001b[?25h ave\u001b[?25l\u001b[?25hz\u001b[?25l\u001b[?25h bes\u001b[?25l\u001b[?25hoin\u001b[?25l\u001b[?25h d\u001b[?25l\u001b[?25h'\u001b[?25l\u001b[?25hin\u001b[?25l\u001b[?25hform\u001b[?25l\u001b[?25hations\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h je\u001b[?25l\u001b[?25h pe\u001b[?25l\u001b[?25hux\u001b[?25l\u001b[?25h t\u001b[?25l\u001b[?25henter\u001b[?25l\u001b[?25h de\u001b[?25l\u001b[?25h les\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25hider\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h mais\u001b[?25l\u001b[?25h pour\u001b[?25l\u001b[?25h tout\u001b[?25l\u001b[?25h sympt\u001b[?25l\u001b[?25hôme\u001b[?25l\u001b[?25h série\u001b[?25l\u001b[?25hux\u001b[?25l\u001b[?25h ou\u001b[?25l\u001b[?25h ur\u001b[?25l\u001b[?25hgent\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h il\u001b[?25l\u001b[?25h est\u001b[?25l\u001b[?25h toujours\u001b[?25l\u001b[?25h pré\u001b[?25l\u001b[?25hf\u001b[?25l\u001b[?25héra\u001b[?25l\u001b[?25hble\u001b[?25l\u001b[?25h d\u001b[?25l\u001b[?25h'\u001b[?25l\u001b[?25hag\u001b[?25l\u001b[?25hir\u001b[?25l\u001b[?25h avec\u001b[?25l\u001b[?25h l\u001b[?25l\u001b[?25h'\u001b[?25l\u001b[?25ha\u001b[?25l\u001b[?25hide\u001b[?25l\u001b[?25h d\u001b[?25l\u001b[?25h'\u001b[?25l\u001b[?25hun\u001b[?25l\u001b[?25h profession\u001b[?25l\u001b[?25hnel\u001b[?25l\u001b[?25h méd\u001b[?25l\u001b[?25hical\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h Pour\u001b[?25l\u001b[?25hrie\u001b[?25l\u001b[?25hz\u001b[?25l\u001b[?25h-\u001b[?25l\u001b[?25hvous\u001b[?25l\u001b[?25h me\u001b[?25l\u001b[?25h dire\u001b[?25l\u001b[?25h comment\u001b[?25l\u001b[?25h puis\u001b[?25l\u001b[?25h-\u001b[?25l\u001b[?25hje\u001b[?25l\u001b[?25h vous\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25hider\u001b[?25l\u001b[?25h aujourd\u001b[?25l\u001b[?25h'\u001b[?25l\u001b[?25hhui\u001b[?25l\u001b[?25h?\u001b[?25l\u001b[?25h\n",
            "\n",
            "\u001b[?25l\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!ollama run phi3:mini \"Bonjour, tu peux m'aider avec des questions médicales?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_wD9uDu1T4D"
      },
      "source": [
        "# Medical Chatbot Core Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fyu7A2mN1Wsd"
      },
      "source": [
        "Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlngQJA91U-j",
        "outputId": "26a9299f-bf6e-4b17-c6c7-df8edcf66be9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ollama\n",
            "  Downloading ollama-0.5.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.12)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.3)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.11-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Collecting mysql-connector-python\n",
            "  Downloading mysql_connector_python-9.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: httpx>=0.27 in /usr/local/lib/python3.11/dist-packages (from ollama) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.11/dist-packages (from ollama) (2.11.5)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.14.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.32.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.12)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->ollama) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->ollama) (1.0.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->ollama) (0.4.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading ollama-0.5.1-py3-none-any.whl (13 kB)\n",
            "Downloading pyngrok-7.2.11-py3-none-any.whl (25 kB)\n",
            "Downloading mysql_connector_python-9.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (33.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.9/33.9 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyngrok, mysql-connector-python, ollama\n",
            "Successfully installed mysql-connector-python-9.3.0 ollama-0.5.1 pyngrok-7.2.11\n"
          ]
        }
      ],
      "source": [
        "!pip install ollama fastapi uvicorn pyngrok gradio mysql-connector-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_A3Uumn1dzC"
      },
      "source": [
        "Medical Chatbot Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8RDPgit1ilf",
        "outputId": "501fc05f-5c53-41d3-ac3b-6669f46ebffa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Database initialized\n",
            "✅ Medical Chatbot initialized\n",
            "🚀 Starting Medical Chatbot API Server...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [2611]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "ERROR:    [Errno 98] error while attempting to bind on address ('0.0.0.0', 8000): address already in use\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⏳ Waiting for server to start...\n",
            "🌐 Setting up ngrok authentication...\n",
            "✅ ngrok authentication configured\n",
            "🌐 Creating public URL with ngrok...\n",
            "\n",
            "        ✅ SUCCESS! Your Medical Chatbot API is now running!\n",
            "        \n",
            "        📍 Local URL: http://localhost:8000\n",
            "        🌐 Public URL: NgrokTunnel: \"https://f56b-34-125-17-230.ngrok-free.app\" -> \"http://localhost:8000\"\n",
            "        📖 API Documentation: NgrokTunnel: \"https://f56b-34-125-17-230.ngrok-free.app\" -> \"http://localhost:8000\"/docs\n",
            "        🔍 Health Check: NgrokTunnel: \"https://f56b-34-125-17-230.ngrok-free.app\" -> \"http://localhost:8000\"/\n",
            "        💬 Chat Endpoint: NgrokTunnel: \"https://f56b-34-125-17-230.ngrok-free.app\" -> \"http://localhost:8000\"/chat\n",
            "        \n",
            "        ⚠️ IMPORTANT: Copy this URL to your Windows .env file:\n",
            "        COLAB_API_URL=NgrokTunnel: \"https://f56b-34-125-17-230.ngrok-free.app\" -> \"http://localhost:8000\"\n",
            "        \n",
            "        🔧 Test your API:\n",
            "        curl NgrokTunnel: \"https://f56b-34-125-17-230.ngrok-free.app\" -> \"http://localhost:8000\"/\n",
            "        \n",
            "💾 API URLs saved to 'api_url.txt' file\n",
            "🧪 Testing API connection...\n",
            "⚠️ API test failed: No connection adapters were found for 'NgrokTunnel: \"https://f56b-34-125-17-230.ngrok-free.app\" -> \"http://localhost:8000\"/'\n",
            "   This might be normal if the tunnel is still starting up\n",
            "\n",
            "    🎉 Setup Complete! \n",
            "    \n",
            "    Next steps:\n",
            "    1. Copy this URL: NgrokTunnel: \"https://f56b-34-125-17-230.ngrok-free.app\" -> \"http://localhost:8000\"\n",
            "    2. Add to your Windows .env file: COLAB_API_URL=NgrokTunnel: \"https://f56b-34-125-17-230.ngrok-free.app\" -> \"http://localhost:8000\"\n",
            "    3. Set COLAB_ENABLED=true in your .env file\n",
            "    4. Restart your Windows backend server\n",
            "    5. Test the integration!\n",
            "    \n",
            "    ⚠️ Keep this Colab notebook running for the API to work!\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# GOOGLE COLAB MEDICAL CHATBOT - COMPLETE INTEGRATION\n",
        "# Copy this entire code to your Google Colab notebook\n",
        "# ============================================================================\n",
        "\n",
        "import ollama\n",
        "import json\n",
        "import sqlite3\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "import re\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel\n",
        "from typing import Optional, List\n",
        "import uvicorn\n",
        "import threading\n",
        "from pyngrok import ngrok\n",
        "import time\n",
        "\n",
        "# ============================================================================\n",
        "# MEDICAL CHATBOT CLASS (Keep your existing class - it's perfect!)\n",
        "# ============================================================================\n",
        "\n",
        "class MedicalChatbotColab:\n",
        "    def __init__(self):\n",
        "        self.client = ollama.Client()\n",
        "        self.setup_database()\n",
        "        self.medical_specialists = {\n",
        "            'neurologue': ['tête', 'vertige', 'migraine', 'neurologique', 'mal de tête'],\n",
        "            'cardiologue': ['cœur', 'poitrine', 'palpitation', 'cardiaque', 'thorax'],\n",
        "            'gastro-entérologue': ['ventre', 'estomac', 'digestif', 'nausée', 'abdomen'],\n",
        "            'dermatologue': ['peau', 'éruption', 'dermatologique', 'acné'],\n",
        "            'gynécologue': ['menstruel', 'gynécologique', 'femme', 'règles', 'utérus'],\n",
        "            'urologue': ['urinaire', 'rein', 'vessie', 'prostate'],\n",
        "            'pneumologue': ['respiration', 'poumon', 'toux', 'asthme'],\n",
        "            'rhumatologue': ['articulation', 'douleur', 'arthrite', 'os'],\n",
        "            'endocrinologue': ['diabète', 'thyroïde', 'hormonal', 'sucre'],\n",
        "            'psychiatre': ['anxiété', 'dépression', 'mental', 'stress'],\n",
        "            'orl': ['oreille', 'nez', 'gorge', 'sinusite'],\n",
        "            'ophtalmologue': ['yeux', 'vision', 'vue', 'œil'],\n",
        "            'médecin généraliste': ['général', 'consultation', 'fatigue']\n",
        "        }\n",
        "\n",
        "    def setup_database(self):\n",
        "        \"\"\"Initialize SQLite database for Colab\"\"\"\n",
        "        self.conn = sqlite3.connect('medical_chatbot.db', check_same_thread=False)\n",
        "        cursor = self.conn.cursor()\n",
        "\n",
        "        # Create chat_history table\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS chat_history (\n",
        "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                conversation_id TEXT NOT NULL,\n",
        "                patient_id TEXT NOT NULL,\n",
        "                message TEXT NOT NULL,\n",
        "                sender TEXT CHECK(sender IN ('user', 'assistant')) NOT NULL,\n",
        "                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        # Create index for performance\n",
        "        cursor.execute('''\n",
        "            CREATE INDEX IF NOT EXISTS idx_conversation_patient\n",
        "            ON chat_history(conversation_id, patient_id)\n",
        "        ''')\n",
        "\n",
        "        self.conn.commit()\n",
        "        print(\"✅ Database initialized\")\n",
        "\n",
        "    def get_conversation_history(self, conversation_id, patient_id, limit=20):\n",
        "        \"\"\"Retrieve conversation history\"\"\"\n",
        "        cursor = self.conn.cursor()\n",
        "        cursor.execute('''\n",
        "            SELECT message, sender, timestamp FROM chat_history\n",
        "            WHERE conversation_id = ? AND patient_id = ?\n",
        "            ORDER BY timestamp ASC LIMIT ?\n",
        "        ''', (conversation_id, patient_id, limit))\n",
        "\n",
        "        return cursor.fetchall()\n",
        "\n",
        "    def save_message(self, conversation_id, patient_id, message, sender):\n",
        "        \"\"\"Save message to database\"\"\"\n",
        "        cursor = self.conn.cursor()\n",
        "        cursor.execute('''\n",
        "            INSERT INTO chat_history (conversation_id, patient_id, message, sender)\n",
        "            VALUES (?, ?, ?, ?)\n",
        "        ''', (conversation_id, patient_id, message, sender))\n",
        "        self.conn.commit()\n",
        "\n",
        "    def detect_medical_specialty(self, message):\n",
        "        \"\"\"Detect appropriate medical specialist\"\"\"\n",
        "        message_lower = message.lower()\n",
        "\n",
        "        for specialist, keywords in self.medical_specialists.items():\n",
        "            for keyword in keywords:\n",
        "                if keyword in message_lower:\n",
        "                    return specialist, f\"pour les problèmes de {keyword}\"\n",
        "\n",
        "        return \"médecin généraliste\", \"pour une consultation générale\"\n",
        "\n",
        "    def format_bold_text(self, text):\n",
        "        \"\"\"Add bold formatting to important medical terms\"\"\"\n",
        "        medical_terms = [\n",
        "            'urgent', 'important', 'consultation', 'médecin', 'docteur',\n",
        "            'symptômes', 'douleur', 'traitement', 'médicament', 'urgence',\n",
        "            'neurologue', 'cardiologue', 'gastro-entérologue', 'dermatologue',\n",
        "            'gynécologue', 'urologue', 'pneumologue', 'rhumatologue',\n",
        "            'endocrinologue', 'psychiatre', 'orl', 'ophtalmologue',\n",
        "            '24h', '48h', '72h', 'heures', 'jours', 'semaines'\n",
        "        ]\n",
        "\n",
        "        for term in medical_terms:\n",
        "            # Case-insensitive replacement with bold formatting\n",
        "            pattern = re.compile(re.escape(term), re.IGNORECASE)\n",
        "            text = pattern.sub(f'**{term}**', text)\n",
        "\n",
        "        return text\n",
        "\n",
        "    def generate_medical_response(self, message, conversation_id, patient_id, language=\"fr\"):\n",
        "        \"\"\"Generate medical response with context and recommendations\"\"\"\n",
        "        try:\n",
        "            # Get conversation history\n",
        "            history = self.get_conversation_history(conversation_id, patient_id)\n",
        "\n",
        "            # Build conversation context\n",
        "            system_prompt = \"\"\"Tu es un assistant médical IA spécialisé en français. Tes réponses doivent:\n",
        "\n",
        "1. TOUJOURS inclure des disclaimers médicaux appropriés\n",
        "2. Recommander des spécialistes médicaux quand nécessaire\n",
        "3. Utiliser un formatage en gras pour les informations importantes\n",
        "4. Ne JAMAIS donner de diagnostic direct\n",
        "5. Être empathique et professionnel\n",
        "6. Répondre en français ou darija marocain selon la langue de l'utilisateur\n",
        "7. Te souvenir de l'historique de conversation pour éviter de répéter les mêmes questions\n",
        "\n",
        "Format de réponse souhaité:\n",
        "- Réponse empathique à la question\n",
        "- Conseils généraux appropriés\n",
        "- 👨‍⚕️ **Recommandation médicale**: [Spécialiste recommandé]\n",
        "- ⚠️ **Rappel**: Consultez toujours un **professionnel de santé**\"\"\"\n",
        "\n",
        "            if language == \"ar\":\n",
        "                system_prompt = \"\"\"أنت مساعد طبي ذكي متخصص في اللغة العربية والدارجة المغربية. يجب أن تكون إجاباتك:\n",
        "\n",
        "1. تتضمن دائماً تنبيهات طبية مناسبة\n",
        "2. توصي بالأطباء المختصين عند الضرورة\n",
        "3. تستخدم التنسيق الغامق للمعلومات المهمة\n",
        "4. لا تعطي تشخيصاً مباشراً أبداً\n",
        "5. تكون متعاطفة ومهنية\n",
        "6. تجيب بالدارجة المغربية\n",
        "7. تتذكر تاريخ المحادثة لتجنب تكرار نفس الأسئلة\n",
        "\n",
        "تنسيق الإجابة المطلوب:\n",
        "- إجابة متعاطفة للسؤال\n",
        "- نصائح عامة مناسبة\n",
        "- 👨‍⚕️ **نصيحة طبية**: [الطبيب المختص الموصى به]\n",
        "- ⚠️ **تذكير**: شوف دائماً **طبيب مختص**\"\"\"\n",
        "\n",
        "            context_messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
        "\n",
        "            # Add conversation history\n",
        "            for msg, sender, timestamp in history:\n",
        "                role = \"user\" if sender == \"user\" else \"assistant\"\n",
        "                context_messages.append({\"role\": role, \"content\": msg})\n",
        "\n",
        "            # Add current message\n",
        "            context_messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "            # Generate response using phi3:mini\n",
        "            response = self.client.chat(\n",
        "                model='phi3:mini',\n",
        "                messages=context_messages,\n",
        "                options={\n",
        "                    \"temperature\": 0.7,\n",
        "                    \"top_p\": 0.9,\n",
        "                    \"max_tokens\": 500\n",
        "                }\n",
        "            )\n",
        "\n",
        "            ai_response = response['message']['content']\n",
        "\n",
        "            # Detect and add specialist recommendation if not present\n",
        "            if \"👨‍⚕️\" not in ai_response:\n",
        "                specialist, reason = self.detect_medical_specialty(message)\n",
        "                if language == \"ar\":\n",
        "                    specialist_recommendation = f\"\\n\\n👨‍⚕️ **نصيحة طبية**: نصحك تشوف **{specialist}** {reason}.\"\n",
        "                else:\n",
        "                    specialist_recommendation = f\"\\n\\n👨‍⚕️ **Recommandation médicale**: Je vous conseille de consulter un **{specialist}** {reason}.\"\n",
        "                ai_response += specialist_recommendation\n",
        "\n",
        "            # Add medical disclaimer if not present\n",
        "            disclaimer_check = \"professionnel de santé\" if language == \"fr\" else \"طبيب مختص\"\n",
        "            if disclaimer_check not in ai_response.lower():\n",
        "                if language == \"ar\":\n",
        "                    ai_response += \"\\n\\n⚠️ **تذكير**: هاد المحادثة غير للمعلومات فقط. **شوف طبيب مختص** لأي مشكل صحي.\"\n",
        "                else:\n",
        "                    ai_response += \"\\n\\n⚠️ **Rappel**: Cette conversation est à titre informatif uniquement. **Consultez un professionnel de santé** pour tout problème médical.\"\n",
        "\n",
        "            # Format bold text\n",
        "            ai_response = self.format_bold_text(ai_response)\n",
        "\n",
        "            # Save messages to database\n",
        "            self.save_message(conversation_id, patient_id, message, 'user')\n",
        "            self.save_message(conversation_id, patient_id, ai_response, 'assistant')\n",
        "\n",
        "            return {\n",
        "                \"response\": ai_response,\n",
        "                \"conversation_id\": conversation_id,\n",
        "                \"status\": \"success\",\n",
        "                \"timestamp\": datetime.now().isoformat()\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Désolé, une erreur s'est produite: {str(e)}. Veuillez réessayer.\"\n",
        "            return {\n",
        "                \"response\": error_msg,\n",
        "                \"conversation_id\": conversation_id,\n",
        "                \"status\": \"error\",\n",
        "                \"timestamp\": datetime.now().isoformat()\n",
        "            }\n",
        "\n",
        "# ============================================================================\n",
        "# FASTAPI MODELS (Required for your Windows backend integration)\n",
        "# ============================================================================\n",
        "\n",
        "class ChatRequest(BaseModel):\n",
        "    message: str\n",
        "    conversation_id: Optional[str] = None\n",
        "    patient_id: Optional[str] = \"default_patient\"\n",
        "    language: Optional[str] = \"fr\"\n",
        "\n",
        "class ChatResponse(BaseModel):\n",
        "    response: str\n",
        "    conversation_id: str\n",
        "    patient_id: str\n",
        "    status: str\n",
        "    timestamp: str\n",
        "\n",
        "class HealthResponse(BaseModel):\n",
        "    status: str\n",
        "    model: str\n",
        "    server: str\n",
        "    timestamp: str\n",
        "\n",
        "# ============================================================================\n",
        "# FASTAPI APPLICATION (This is what your Windows app will connect to)\n",
        "# ============================================================================\n",
        "\n",
        "# Initialize the medical chatbot\n",
        "medical_bot = MedicalChatbotColab()\n",
        "print(\"✅ Medical Chatbot initialized\")\n",
        "\n",
        "# Create FastAPI app\n",
        "app = FastAPI(\n",
        "    title=\"Medical Chatbot API - Google Colab\",\n",
        "    description=\"AI Medical Assistant API powered by phi3:mini on Google Colab\",\n",
        "    version=\"1.0.0\"\n",
        ")\n",
        "\n",
        "# Add CORS middleware for Windows app integration\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],  # Configure this for production\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "@app.get(\"/\", response_model=HealthResponse)\n",
        "async def health_check():\n",
        "    \"\"\"Health check endpoint - Your Windows app will use this to test connection\"\"\"\n",
        "    return HealthResponse(\n",
        "        status=\"healthy\",\n",
        "        model=\"phi3:mini\",\n",
        "        server=\"Google Colab\",\n",
        "        timestamp=datetime.now().isoformat()\n",
        "    )\n",
        "\n",
        "@app.post(\"/chat\", response_model=ChatResponse)\n",
        "async def chat_endpoint(request: ChatRequest):\n",
        "    \"\"\"Main chat endpoint - Your Windows app will send messages here\"\"\"\n",
        "    try:\n",
        "        # Generate conversation ID if not provided\n",
        "        conversation_id = request.conversation_id or str(uuid.uuid4())\n",
        "\n",
        "        # Generate response\n",
        "        result = medical_bot.generate_medical_response(\n",
        "            request.message,\n",
        "            conversation_id,\n",
        "            request.patient_id,\n",
        "            request.language\n",
        "        )\n",
        "\n",
        "        if result[\"status\"] == \"success\":\n",
        "            return ChatResponse(\n",
        "                response=result[\"response\"],\n",
        "                conversation_id=conversation_id,\n",
        "                patient_id=request.patient_id,\n",
        "                status=\"success\",\n",
        "                timestamp=result[\"timestamp\"]\n",
        "            )\n",
        "        else:\n",
        "            raise HTTPException(status_code=500, detail=result[\"response\"])\n",
        "\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.get(\"/conversations/{conversation_id}\")\n",
        "async def get_conversation_history(conversation_id: str, patient_id: str = \"default_patient\"):\n",
        "    \"\"\"Get conversation history - Your Windows app can retrieve chat history\"\"\"\n",
        "    try:\n",
        "        history = medical_bot.get_conversation_history(conversation_id, patient_id)\n",
        "        return {\n",
        "            \"conversation_id\": conversation_id,\n",
        "            \"patient_id\": patient_id,\n",
        "            \"history\": [\n",
        "                {\n",
        "                    \"message\": msg,\n",
        "                    \"sender\": sender,\n",
        "                    \"timestamp\": timestamp\n",
        "                }\n",
        "                for msg, sender, timestamp in history\n",
        "            ]\n",
        "        }\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.post(\"/reset-conversation\")\n",
        "async def reset_conversation():\n",
        "    \"\"\"Create new conversation ID\"\"\"\n",
        "    new_conversation_id = str(uuid.uuid4())\n",
        "    return {\n",
        "        \"conversation_id\": new_conversation_id,\n",
        "        \"status\": \"success\",\n",
        "        \"message\": \"New conversation started\",\n",
        "        \"timestamp\": datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "# ============================================================================\n",
        "# SERVER STARTUP (This creates your API URL)\n",
        "# ============================================================================\n",
        "\n",
        "def start_api_server():\n",
        "    \"\"\"Start the FastAPI server and create public URL\"\"\"\n",
        "\n",
        "    print(\"🚀 Starting Medical Chatbot API Server...\")\n",
        "\n",
        "    # Start FastAPI server in background\n",
        "    def run_fastapi_server():\n",
        "        uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
        "\n",
        "    # Start server in background thread\n",
        "    server_thread = threading.Thread(target=run_fastapi_server, daemon=True)\n",
        "    server_thread.start()\n",
        "\n",
        "    # Wait for server to start\n",
        "    print(\"⏳ Waiting for server to start...\")\n",
        "    time.sleep(8)\n",
        "\n",
        "    # Create public URL with ngrok\n",
        "    try:\n",
        "        print(\"🌐 Setting up ngrok authentication...\")\n",
        "\n",
        "        # IMPORTANT: Replace 'YOUR_NGROK_AUTHTOKEN_HERE' with your actual ngrok authtoken\n",
        "        # Get your authtoken from: https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "        NGROK_AUTHTOKEN = \"2yTHefwwJgvXH834l9PEBvLdDfn_4bLeVXGdDd63rmgmgcLAd\"  # ⚠️ REPLACE THIS WITH YOUR ACTUAL TOKEN\n",
        "\n",
        "        if NGROK_AUTHTOKEN == \"YOUR_NGROK_AUTHTOKEN_HERE\":\n",
        "            print(\"❌ ERROR: You need to replace 'YOUR_NGROK_AUTHTOKEN_HERE' with your actual ngrok authtoken!\")\n",
        "            print(\"📋 Steps to fix this:\")\n",
        "            print(\"1. Go to: https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "            print(\"2. Copy your authtoken\")\n",
        "            print(\"3. Replace 'YOUR_NGROK_AUTHTOKEN_HERE' in the code above with your token\")\n",
        "            print(\"4. Re-run this cell\")\n",
        "            return None\n",
        "\n",
        "        # Set the ngrok authtoken\n",
        "        ngrok.set_auth_token(NGROK_AUTHTOKEN)\n",
        "        print(\"✅ ngrok authentication configured\")\n",
        "\n",
        "        print(\"🌐 Creating public URL with ngrok...\")\n",
        "        public_url = ngrok.connect(8000)\n",
        "\n",
        "        print(f\"\"\"\n",
        "        ✅ SUCCESS! Your Medical Chatbot API is now running!\n",
        "\n",
        "        📍 Local URL: http://localhost:8000\n",
        "        🌐 Public URL: {public_url}\n",
        "        📖 API Documentation: {public_url}/docs\n",
        "        🔍 Health Check: {public_url}/\n",
        "        💬 Chat Endpoint: {public_url}/chat\n",
        "\n",
        "        ⚠️ IMPORTANT: Copy this URL to your Windows .env file:\n",
        "        COLAB_API_URL={public_url}\n",
        "\n",
        "        🔧 Test your API:\n",
        "        curl {public_url}/\n",
        "        \"\"\")\n",
        "\n",
        "        # Save URL to file for easy access\n",
        "        with open('api_url.txt', 'w') as f:\n",
        "            f.write(f\"COLAB_API_URL={public_url}\\n\")\n",
        "            f.write(f\"DOCS_URL={public_url}/docs\\n\")\n",
        "            f.write(f\"HEALTH_URL={public_url}/\\n\")\n",
        "            f.write(f\"CHAT_URL={public_url}/chat\\n\")\n",
        "\n",
        "        print(\"💾 API URLs saved to 'api_url.txt' file\")\n",
        "\n",
        "        # Test the API to make sure it's working\n",
        "        print(\"🧪 Testing API connection...\")\n",
        "        try:\n",
        "            import requests\n",
        "            response = requests.get(f\"{public_url}/\", timeout=10)\n",
        "            if response.status_code == 200:\n",
        "                print(\"✅ API test successful!\")\n",
        "                print(f\"   Response: {response.json()}\")\n",
        "            else:\n",
        "                print(f\"⚠️ API test returned status code: {response.status_code}\")\n",
        "        except Exception as test_error:\n",
        "            print(f\"⚠️ API test failed: {test_error}\")\n",
        "            print(\"   This might be normal if the tunnel is still starting up\")\n",
        "\n",
        "        return public_url\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error creating public URL: {e}\")\n",
        "        print(\"💡 Troubleshooting steps:\")\n",
        "        print(\"   1. Make sure you replaced 'YOUR_NGROK_AUTHTOKEN_HERE' with your actual token\")\n",
        "        print(\"   2. Check your internet connection\")\n",
        "        print(\"   3. Verify your ngrok authtoken is correct\")\n",
        "        print(\"   4. You can still use the local URL: http://localhost:8000\")\n",
        "        return None\n",
        "\n",
        "# ============================================================================\n",
        "# ALTERNATIVE: Manual ngrok setup function\n",
        "# ============================================================================\n",
        "\n",
        "def setup_ngrok_manually():\n",
        "    \"\"\"Alternative function to set up ngrok manually if the automatic setup fails\"\"\"\n",
        "    print(\"🔧 Manual ngrok setup:\")\n",
        "    print(\"1. Replace the authtoken in the code above\")\n",
        "    print(\"2. Or run this in a new cell:\")\n",
        "    print(\"\"\"\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Set your authtoken (replace with your actual token)\n",
        "ngrok.set_auth_token(\"your_actual_authtoken_here\")\n",
        "\n",
        "# Create tunnel\n",
        "public_url = ngrok.connect(8000)\n",
        "print(f\"🌐 Your API URL: {public_url}\")\n",
        "\n",
        "# Save to file\n",
        "with open('api_url.txt', 'w') as f:\n",
        "    f.write(f\"COLAB_API_URL={public_url}\\\\n\")\n",
        "\n",
        "print(\"✅ Done! Copy the URL to your .env file\")\n",
        "    \"\"\")\n",
        "\n",
        "# ============================================================================\n",
        "# START THE API SERVER\n",
        "# ============================================================================\n",
        "\n",
        "# Start the server automatically\n",
        "api_url = start_api_server()\n",
        "\n",
        "if api_url:\n",
        "    print(f\"\"\"\n",
        "    🎉 Setup Complete!\n",
        "\n",
        "    Next steps:\n",
        "    1. Copy this URL: {api_url}\n",
        "    2. Add to your Windows .env file: COLAB_API_URL={api_url}\n",
        "    3. Set COLAB_ENABLED=true in your .env file\n",
        "    4. Restart your Windows backend server\n",
        "    5. Test the integration!\n",
        "\n",
        "    ⚠️ Keep this Colab notebook running for the API to work!\n",
        "    \"\"\")\n",
        "else:\n",
        "    print(\"\"\"\n",
        "    ⚠️ Public URL creation failed, but local server is running.\n",
        "\n",
        "    🔧 To fix this:\n",
        "    1. Replace 'YOUR_NGROK_AUTHTOKEN_HERE' with your actual ngrok authtoken\n",
        "    2. Re-run this cell\n",
        "\n",
        "    Or use the manual setup function: setup_ngrok_manually()\n",
        "    \"\"\")\n",
        "\n",
        "    # Show manual setup instructions\n",
        "    setup_ngrok_manually()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w4oEpDAUa3G",
        "outputId": "0ee0db1d-a153-425e-fe11-0fa566fc7b31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🌐 Clean API URL: https://f56b-34-125-17-230.ngrok-free.app\n",
            "INFO:     34.125.17.230:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "✅ API test successful!\n",
            "   Response: {'status': 'healthy', 'model': 'phi3:mini', 'server': 'Google Colab', 'timestamp': '2025-06-13T22:03:29.431286'}\n",
            "\n",
            "    ✅ FIXED! Use this clean URL:\n",
            "    \n",
            "    🌐 API URL: https://f56b-34-125-17-230.ngrok-free.app\n",
            "    📖 Documentation: https://f56b-34-125-17-230.ngrok-free.app/docs\n",
            "    \n",
            "    📋 ADD THIS TO YOUR .ENV FILE:\n",
            "    COLAB_API_URL=https://f56b-34-125-17-230.ngrok-free.app\n",
            "    COLAB_ENABLED=true\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "# Fix the ngrok URL format and test the API\n",
        "from pyngrok import ngrok\n",
        "import requests\n",
        "\n",
        "# Get the clean URL\n",
        "tunnels = ngrok.get_tunnels()\n",
        "if tunnels:\n",
        "    clean_url = tunnels[0].public_url\n",
        "    print(f\"🌐 Clean API URL: {clean_url}\")\n",
        "\n",
        "    # Test the API properly\n",
        "    try:\n",
        "        response = requests.get(f\"{clean_url}/\", timeout=10)\n",
        "        if response.status_code == 200:\n",
        "            print(\"✅ API test successful!\")\n",
        "            print(f\"   Response: {response.json()}\")\n",
        "        else:\n",
        "            print(f\"⚠️ API returned status: {response.status_code}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ API test failed: {e}\")\n",
        "\n",
        "    # Save the clean URL\n",
        "    with open('api_url_clean.txt', 'w') as f:\n",
        "        f.write(f\"COLAB_API_URL={clean_url}\\n\")\n",
        "        f.write(f\"DOCS_URL={clean_url}/docs\\n\")\n",
        "        f.write(f\"HEALTH_URL={clean_url}/\\n\")\n",
        "        f.write(f\"CHAT_URL={clean_url}/chat\\n\")\n",
        "\n",
        "    print(f\"\"\"\n",
        "    ✅ FIXED! Use this clean URL:\n",
        "\n",
        "    🌐 API URL: {clean_url}\n",
        "    📖 Documentation: {clean_url}/docs\n",
        "\n",
        "    📋 ADD THIS TO YOUR .ENV FILE:\n",
        "    COLAB_API_URL={clean_url}\n",
        "    COLAB_ENABLED=true\n",
        "    \"\"\")\n",
        "else:\n",
        "    print(\"❌ No active tunnels found\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
